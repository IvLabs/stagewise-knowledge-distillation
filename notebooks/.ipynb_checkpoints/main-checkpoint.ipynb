{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "tfms = get_transforms(do_flip=False)\n",
    "data = ImageDataBunch.from_folder(path, train = 'train', valid = 'val', bs = batch_size, size = 224, ds_tfms = tfms).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on GPU\n"
     ]
    }
   ],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics = accuracy)\n",
    "learn = learn.load('unfreeze_imagenet_bs64')\n",
    "# learn.summary()\n",
    "\n",
    "class Flatten(nn.Module) :\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def conv2(ni, nf) : \n",
    "    return conv_layer(ni, nf, stride = 2)\n",
    "\n",
    "def conv_and_res(ni, nf): \n",
    "    return nn.Sequential(conv2(ni, nf), res_block(nf))\n",
    "    \n",
    "net = nn.Sequential(\n",
    "    conv_and_res(3, 8),\n",
    "    conv_and_res(8, 16),\n",
    "    conv_and_res(16, 32),\n",
    "    conv_and_res(32, 16),\n",
    "    conv2(16, 10),\n",
    "    Flatten()\n",
    ")\n",
    "        \n",
    "# net = CNN()\n",
    "if torch.cuda.is_available() : \n",
    "    net = net.cuda()\n",
    "    print('Model on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 112, 112]             216\n",
      "              ReLU-2          [-1, 8, 112, 112]               0\n",
      "       BatchNorm2d-3          [-1, 8, 112, 112]              16\n",
      "            Conv2d-4          [-1, 8, 112, 112]             576\n",
      "              ReLU-5          [-1, 8, 112, 112]               0\n",
      "       BatchNorm2d-6          [-1, 8, 112, 112]              16\n",
      "            Conv2d-7          [-1, 8, 112, 112]             576\n",
      "              ReLU-8          [-1, 8, 112, 112]               0\n",
      "       BatchNorm2d-9          [-1, 8, 112, 112]              16\n",
      "       MergeLayer-10          [-1, 8, 112, 112]               0\n",
      "     SequentialEx-11          [-1, 8, 112, 112]               0\n",
      "           Conv2d-12           [-1, 16, 56, 56]           1,152\n",
      "             ReLU-13           [-1, 16, 56, 56]               0\n",
      "      BatchNorm2d-14           [-1, 16, 56, 56]              32\n",
      "           Conv2d-15           [-1, 16, 56, 56]           2,304\n",
      "             ReLU-16           [-1, 16, 56, 56]               0\n",
      "      BatchNorm2d-17           [-1, 16, 56, 56]              32\n",
      "           Conv2d-18           [-1, 16, 56, 56]           2,304\n",
      "             ReLU-19           [-1, 16, 56, 56]               0\n",
      "      BatchNorm2d-20           [-1, 16, 56, 56]              32\n",
      "       MergeLayer-21           [-1, 16, 56, 56]               0\n",
      "     SequentialEx-22           [-1, 16, 56, 56]               0\n",
      "           Conv2d-23           [-1, 32, 28, 28]           4,608\n",
      "             ReLU-24           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "           Conv2d-26           [-1, 32, 28, 28]           9,216\n",
      "             ReLU-27           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-28           [-1, 32, 28, 28]              64\n",
      "           Conv2d-29           [-1, 32, 28, 28]           9,216\n",
      "             ReLU-30           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-31           [-1, 32, 28, 28]              64\n",
      "       MergeLayer-32           [-1, 32, 28, 28]               0\n",
      "     SequentialEx-33           [-1, 32, 28, 28]               0\n",
      "           Conv2d-34           [-1, 16, 14, 14]           4,608\n",
      "             ReLU-35           [-1, 16, 14, 14]               0\n",
      "      BatchNorm2d-36           [-1, 16, 14, 14]              32\n",
      "           Conv2d-37           [-1, 16, 14, 14]           2,304\n",
      "             ReLU-38           [-1, 16, 14, 14]               0\n",
      "      BatchNorm2d-39           [-1, 16, 14, 14]              32\n",
      "           Conv2d-40           [-1, 16, 14, 14]           2,304\n",
      "             ReLU-41           [-1, 16, 14, 14]               0\n",
      "      BatchNorm2d-42           [-1, 16, 14, 14]              32\n",
      "       MergeLayer-43           [-1, 16, 14, 14]               0\n",
      "     SequentialEx-44           [-1, 16, 14, 14]               0\n",
      "           Conv2d-45             [-1, 10, 7, 7]           1,440\n",
      "             ReLU-46             [-1, 10, 7, 7]               0\n",
      "      BatchNorm2d-47             [-1, 10, 7, 7]              20\n",
      "          Flatten-48                  [-1, 490]               0\n",
      "================================================================\n",
      "Total params: 41,276\n",
      "Trainable params: 41,276\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 15.02\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 15.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# x, y = next(iter(data.train_dl))\n",
    "# net(torch.autograd.Variable(x).cuda())\n",
    "summary(net, (3, 224, 224))\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures :\n",
    "    def __init__(self, m) : \n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp) : \n",
    "        self.features = outp\n",
    "    def remove(self) :\n",
    "        self.handle.remove()\n",
    "        \n",
    "# saving outputs of all Basic Blocks\n",
    "mdl = learn.model\n",
    "sf = [SaveFeatures(m) for m in [mdl[0][2], mdl[0][4], mdl[0][5], mdl[0][6], mdl[0][7]]]\n",
    "sf2 = [SaveFeatures(m) for m in [net[1], net[3], net[5], net[7], net[9]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(data.train_dl))\n",
    "# x = torch.autograd.Variable(x).cuda()\n",
    "# out1 = mdl(x)\n",
    "# out2 = net(x)\n",
    "# for i in range(5) : \n",
    "#     assert(sf[i].features.shape == sf2[i].features.shape)\n",
    "# del x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training using teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  200  of total steps  805  loss =  0.9172264734903971\n",
      "epoch =  0  step =  400  of total steps  805  loss =  0.8226620356241862\n",
      "epoch =  0  step =  600  of total steps  805  loss =  0.9226047197977701\n",
      "epoch =  0  step =  800  of total steps  805  loss =  0.9060332775115967\n",
      "epoch :  1  /  100  | TL :  0.9586156877671722  | VL :  1.1423591375350952\n",
      "saving model\n",
      "epoch =  1  step =  200  of total steps  805  loss =  0.8916026751200358\n",
      "epoch =  1  step =  400  of total steps  805  loss =  0.859843889872233\n",
      "epoch =  1  step =  600  of total steps  805  loss =  0.9872457186381022\n",
      "epoch =  1  step =  800  of total steps  805  loss =  0.8324641386667887\n",
      "epoch :  2  /  100  | TL :  0.8470254914854376  | VL :  1.206603765487671\n",
      "epoch =  2  step =  200  of total steps  805  loss =  0.820203940073649\n",
      "epoch =  2  step =  400  of total steps  805  loss =  0.7824554443359375\n",
      "epoch =  2  step =  600  of total steps  805  loss =  0.772387425104777\n",
      "epoch =  2  step =  800  of total steps  805  loss =  0.7777105967203776\n",
      "epoch :  3  /  100  | TL :  0.7841984619018209  | VL :  1.0291568040847778\n",
      "saving model\n",
      "epoch =  3  step =  200  of total steps  805  loss =  0.7765051523844401\n",
      "epoch =  3  step =  400  of total steps  805  loss =  0.6543300549189249\n",
      "epoch =  3  step =  600  of total steps  805  loss =  0.6410452524820963\n",
      "epoch =  3  step =  800  of total steps  805  loss =  0.7067428429921468\n",
      "epoch :  4  /  100  | TL :  0.7034550377547623  | VL :  0.8895094394683838\n",
      "saving model\n",
      "epoch =  4  step =  200  of total steps  805  loss =  0.688330332438151\n",
      "epoch =  4  step =  400  of total steps  805  loss =  0.6367041269938151\n",
      "epoch =  4  step =  600  of total steps  805  loss =  0.5646006266276041\n",
      "epoch =  4  step =  800  of total steps  805  loss =  0.6927943229675293\n",
      "epoch :  5  /  100  | TL :  0.6654219856420165  | VL :  1.0538100004196167\n",
      "epoch =  5  step =  200  of total steps  805  loss =  0.587470293045044\n",
      "epoch =  5  step =  400  of total steps  805  loss =  0.7521797815958658\n",
      "epoch =  5  step =  600  of total steps  805  loss =  0.5130172570546468\n",
      "epoch =  5  step =  800  of total steps  805  loss =  0.6023561557133993\n",
      "epoch :  6  /  100  | TL :  0.6513518882340782  | VL :  0.93459552526474\n",
      "epoch =  6  step =  200  of total steps  805  loss =  0.6081918080647787\n",
      "epoch =  6  step =  400  of total steps  805  loss =  0.6594284375508627\n",
      "epoch =  6  step =  600  of total steps  805  loss =  0.577508290608724\n",
      "epoch =  6  step =  800  of total steps  805  loss =  0.7296985785166422\n",
      "epoch :  7  /  100  | TL :  0.6439846279211413  | VL :  1.1170220375061035\n",
      "epoch =  7  step =  200  of total steps  805  loss =  0.6445903778076172\n",
      "epoch =  7  step =  400  of total steps  805  loss =  0.6727141539255778\n",
      "epoch =  7  step =  600  of total steps  805  loss =  0.6120675404866537\n",
      "epoch =  7  step =  800  of total steps  805  loss =  0.570056676864624\n",
      "epoch :  8  /  100  | TL :  0.6368017819604028  | VL :  0.8672391772270203\n",
      "saving model\n",
      "epoch =  8  step =  200  of total steps  805  loss =  0.7583607832590739\n",
      "epoch =  8  step =  400  of total steps  805  loss =  0.5798790454864502\n",
      "epoch =  8  step =  600  of total steps  805  loss =  0.6361875534057617\n",
      "epoch =  8  step =  800  of total steps  805  loss =  0.5165362358093262\n",
      "epoch :  9  /  100  | TL :  0.6241006583654121  | VL :  0.8967252969741821\n",
      "epoch =  9  step =  200  of total steps  805  loss =  0.5520938634872437\n",
      "epoch =  9  step =  400  of total steps  805  loss =  0.6162482500076294\n",
      "epoch =  9  step =  600  of total steps  805  loss =  0.5528215964635214\n",
      "epoch =  9  step =  800  of total steps  805  loss =  0.7311410109202067\n",
      "epoch :  10  /  100  | TL :  0.6190093609610454  | VL :  0.9116008877754211\n",
      "epoch =  10  step =  200  of total steps  805  loss =  0.6641208330790201\n",
      "epoch =  10  step =  400  of total steps  805  loss =  0.5368392070134481\n",
      "epoch =  10  step =  600  of total steps  805  loss =  0.5567102829615275\n",
      "epoch =  10  step =  800  of total steps  805  loss =  0.5423703193664551\n",
      "epoch :  11  /  100  | TL :  0.6185830766863455  | VL :  0.8102563619613647\n",
      "saving model\n",
      "epoch =  11  step =  200  of total steps  805  loss =  0.5518786112467448\n",
      "epoch =  11  step =  400  of total steps  805  loss =  0.674048105875651\n",
      "epoch =  11  step =  600  of total steps  805  loss =  0.6008774439493815\n",
      "epoch =  11  step =  800  of total steps  805  loss =  0.629024346669515\n",
      "epoch :  12  /  100  | TL :  0.6100720124215068  | VL :  0.7716907858848572\n",
      "saving model\n",
      "epoch =  12  step =  200  of total steps  805  loss =  0.5094069639841715\n",
      "epoch =  12  step =  400  of total steps  805  loss =  0.6852509180704752\n",
      "epoch =  12  step =  600  of total steps  805  loss =  0.744893471399943\n",
      "epoch =  12  step =  800  of total steps  805  loss =  0.6539433797200521\n",
      "epoch :  13  /  100  | TL :  0.606093960815335  | VL :  0.735811710357666\n",
      "saving model\n",
      "epoch =  13  step =  200  of total steps  805  loss =  0.5434919595718384\n",
      "epoch =  13  step =  400  of total steps  805  loss =  0.6555227438608805\n",
      "epoch =  13  step =  600  of total steps  805  loss =  0.6401775677998861\n",
      "epoch =  13  step =  800  of total steps  805  loss =  0.5512604316075643\n",
      "epoch :  14  /  100  | TL :  0.6018516037034698  | VL :  0.8289912343025208\n",
      "epoch =  14  step =  200  of total steps  805  loss =  0.655095378557841\n",
      "epoch =  14  step =  400  of total steps  805  loss =  0.5604424476623535\n",
      "epoch =  14  step =  600  of total steps  805  loss =  0.5488147735595703\n",
      "epoch =  14  step =  800  of total steps  805  loss =  0.6233839988708496\n",
      "epoch :  15  /  100  | TL :  0.5979590575393924  | VL :  0.9891898036003113\n",
      "epoch =  15  step =  200  of total steps  805  loss =  0.5247065226236979\n",
      "epoch =  15  step =  400  of total steps  805  loss =  0.5812793572743734\n",
      "epoch =  15  step =  600  of total steps  805  loss =  0.6462900241216024\n",
      "epoch =  15  step =  800  of total steps  805  loss =  0.6133610407511393\n",
      "epoch :  16  /  100  | TL :  0.5950075151510611  | VL :  0.7629885673522949\n",
      "epoch =  16  step =  200  of total steps  805  loss =  0.7022627194722494\n",
      "epoch =  16  step =  400  of total steps  805  loss =  0.6527130206425985\n",
      "epoch =  16  step =  600  of total steps  805  loss =  0.6202672322591146\n",
      "epoch =  16  step =  800  of total steps  805  loss =  0.6088219881057739\n",
      "epoch :  17  /  100  | TL :  0.5869255777224746  | VL :  0.726216733455658\n",
      "saving model\n",
      "epoch =  17  step =  200  of total steps  805  loss =  0.5682067473729452\n",
      "epoch =  17  step =  400  of total steps  805  loss =  0.5710780223210653\n",
      "epoch =  17  step =  600  of total steps  805  loss =  0.5335989395777384\n",
      "epoch =  17  step =  800  of total steps  805  loss =  0.6023781299591064\n",
      "epoch :  18  /  100  | TL :  0.5834826976862995  | VL :  0.8356144428253174\n",
      "epoch =  18  step =  200  of total steps  805  loss =  0.6447024345397949\n",
      "epoch =  18  step =  400  of total steps  805  loss =  0.6810970306396484\n",
      "epoch =  18  step =  600  of total steps  805  loss =  0.5985004901885986\n",
      "epoch =  18  step =  800  of total steps  805  loss =  0.5257633527119955\n",
      "epoch :  19  /  100  | TL :  0.5810556924120978  | VL :  0.6725728511810303\n",
      "saving model\n",
      "epoch =  19  step =  200  of total steps  805  loss =  0.5473062992095947\n",
      "epoch =  19  step =  400  of total steps  805  loss =  0.6058600346247355\n",
      "epoch =  19  step =  600  of total steps  805  loss =  0.6357311407725016\n",
      "epoch =  19  step =  800  of total steps  805  loss =  0.5635422468185425\n",
      "epoch :  20  /  100  | TL :  0.5778202816072705  | VL :  0.6544497013092041\n",
      "saving model\n",
      "epoch =  20  step =  200  of total steps  805  loss =  0.5679945548375448\n",
      "epoch =  20  step =  400  of total steps  805  loss =  0.49656399091084796\n",
      "epoch =  20  step =  600  of total steps  805  loss =  0.6202530463536581\n",
      "epoch =  20  step =  800  of total steps  805  loss =  0.5534966786702474\n",
      "epoch :  21  /  100  | TL :  0.5749936375311939  | VL :  0.738864004611969\n",
      "epoch =  21  step =  200  of total steps  805  loss =  0.647324283917745\n",
      "epoch =  21  step =  400  of total steps  805  loss =  0.5697698990503947\n",
      "epoch =  21  step =  600  of total steps  805  loss =  0.6452040672302246\n",
      "epoch =  21  step =  800  of total steps  805  loss =  0.6207842032114664\n",
      "epoch :  22  /  100  | TL :  0.5748147217630108  | VL :  0.7397709488868713\n",
      "epoch =  22  step =  200  of total steps  805  loss =  0.7557661533355713\n",
      "epoch =  22  step =  400  of total steps  805  loss =  0.4821015199025472\n",
      "epoch =  22  step =  600  of total steps  805  loss =  0.5871233940124512\n",
      "epoch =  22  step =  800  of total steps  805  loss =  0.4791680971781413\n",
      "epoch :  23  /  100  | TL :  0.5711549498279643  | VL :  0.7103357911109924\n",
      "epoch =  23  step =  200  of total steps  805  loss =  0.652271032333374\n",
      "epoch =  23  step =  400  of total steps  805  loss =  0.6455402374267578\n",
      "epoch =  23  step =  600  of total steps  805  loss =  0.531060258547465\n",
      "epoch =  23  step =  800  of total steps  805  loss =  0.58399498462677\n",
      "epoch :  24  /  100  | TL :  0.5662783946556584  | VL :  0.7037990093231201\n",
      "epoch =  24  step =  200  of total steps  805  loss =  0.508307933807373\n",
      "epoch =  24  step =  400  of total steps  805  loss =  0.5609227021535238\n",
      "epoch =  24  step =  600  of total steps  805  loss =  0.5899612108866373\n",
      "epoch =  24  step =  800  of total steps  805  loss =  0.4600173632303874\n",
      "epoch :  25  /  100  | TL :  0.561338378035504  | VL :  0.6723776459693909\n",
      "epoch =  25  step =  200  of total steps  805  loss =  0.5490842262903849\n",
      "epoch =  25  step =  400  of total steps  805  loss =  0.6668514410654703\n",
      "epoch =  25  step =  600  of total steps  805  loss =  0.5929523309071859\n",
      "epoch =  25  step =  800  of total steps  805  loss =  0.5786987543106079\n",
      "epoch :  26  /  100  | TL :  0.5608975652335341  | VL :  0.7215548753738403\n",
      "epoch =  26  step =  200  of total steps  805  loss =  0.5688647429148356\n",
      "epoch =  26  step =  400  of total steps  805  loss =  0.5349783102671305\n",
      "epoch =  26  step =  600  of total steps  805  loss =  0.5720346768697103\n",
      "epoch =  26  step =  800  of total steps  805  loss =  0.5460371971130371\n",
      "epoch :  27  /  100  | TL :  0.5588316176001823  | VL :  0.6492643356323242\n",
      "saving model\n",
      "epoch =  27  step =  200  of total steps  805  loss =  0.6029029687245687\n",
      "epoch =  27  step =  400  of total steps  805  loss =  0.62055770556132\n",
      "epoch =  27  step =  600  of total steps  805  loss =  0.6355183521906534\n",
      "epoch =  27  step =  800  of total steps  805  loss =  0.4858763615290324\n",
      "epoch :  28  /  100  | TL :  0.55407258003148  | VL :  0.6312854290008545\n",
      "saving model\n",
      "epoch =  28  step =  200  of total steps  805  loss =  0.5156966050465902\n",
      "epoch =  28  step =  400  of total steps  805  loss =  0.5933727423350016\n",
      "epoch =  28  step =  600  of total steps  805  loss =  0.5485661029815674\n",
      "epoch =  28  step =  800  of total steps  805  loss =  0.5403183698654175\n",
      "epoch :  29  /  100  | TL :  0.553205159238653  | VL :  0.8175554871559143\n",
      "epoch =  29  step =  200  of total steps  805  loss =  0.5151682694753011\n",
      "epoch =  29  step =  400  of total steps  805  loss =  0.5946168104807535\n",
      "epoch =  29  step =  600  of total steps  805  loss =  0.6070862611134847\n",
      "epoch =  29  step =  800  of total steps  805  loss =  0.5000182787577311\n",
      "epoch :  30  /  100  | TL :  0.5490664970800744  | VL :  0.7023540735244751\n",
      "epoch =  30  step =  200  of total steps  805  loss =  0.47810808817545575\n",
      "epoch =  30  step =  400  of total steps  805  loss =  0.5499481360117594\n",
      "epoch =  30  step =  600  of total steps  805  loss =  0.549190084139506\n",
      "epoch =  30  step =  800  of total steps  805  loss =  0.5525720119476318\n",
      "epoch :  31  /  100  | TL :  0.5501775219326931  | VL :  0.8233445286750793\n",
      "epoch =  31  step =  200  of total steps  805  loss =  0.4857969284057617\n",
      "epoch =  31  step =  400  of total steps  805  loss =  0.5577398935953776\n",
      "epoch =  31  step =  600  of total steps  805  loss =  0.4989064931869507\n",
      "epoch =  31  step =  800  of total steps  805  loss =  0.6041898727416992\n",
      "epoch :  32  /  100  | TL :  0.5455574258760881  | VL :  0.680278480052948\n",
      "epoch =  32  step =  200  of total steps  805  loss =  0.5297589302062988\n",
      "epoch =  32  step =  400  of total steps  805  loss =  0.6207491556803385\n",
      "epoch =  32  step =  600  of total steps  805  loss =  0.5587261120478312\n",
      "epoch =  32  step =  800  of total steps  805  loss =  0.5886476834615072\n",
      "epoch :  33  /  100  | TL :  0.5442000382682053  | VL :  0.6050155758857727\n",
      "saving model\n",
      "epoch =  33  step =  200  of total steps  805  loss =  0.5389424562454224\n",
      "epoch =  33  step =  400  of total steps  805  loss =  0.5819362004597982\n",
      "epoch =  33  step =  600  of total steps  805  loss =  0.6694560845692953\n",
      "epoch =  33  step =  800  of total steps  805  loss =  0.5144818226496378\n",
      "epoch :  34  /  100  | TL :  0.5421417690952371  | VL :  0.6953078508377075\n",
      "epoch =  34  step =  200  of total steps  805  loss =  0.47181665897369385\n",
      "epoch =  34  step =  400  of total steps  805  loss =  0.5372875928878784\n",
      "epoch =  34  step =  600  of total steps  805  loss =  0.4979184071222941\n",
      "epoch =  34  step =  800  of total steps  805  loss =  0.575267473856608\n",
      "epoch :  35  /  100  | TL :  0.5399771243642316  | VL :  0.6822139620780945\n",
      "epoch =  35  step =  200  of total steps  805  loss =  0.6368159850438436\n",
      "epoch =  35  step =  400  of total steps  805  loss =  0.6228926181793213\n",
      "epoch =  35  step =  600  of total steps  805  loss =  0.6475718021392822\n",
      "epoch =  35  step =  800  of total steps  805  loss =  0.6067101955413818\n",
      "epoch :  36  /  100  | TL :  0.5391019513147957  | VL :  0.6883147358894348\n",
      "epoch =  36  step =  200  of total steps  805  loss =  0.6043276389439901\n",
      "epoch =  36  step =  400  of total steps  805  loss =  0.4828503926595052\n",
      "epoch =  36  step =  600  of total steps  805  loss =  0.5411315759023031\n",
      "epoch =  36  step =  800  of total steps  805  loss =  0.48896201451619464\n",
      "epoch :  37  /  100  | TL :  0.533943411479578  | VL :  0.5989184975624084\n",
      "saving model\n",
      "epoch =  37  step =  200  of total steps  805  loss =  0.522403875986735\n",
      "epoch =  37  step =  400  of total steps  805  loss =  0.6207547982533773\n",
      "epoch =  37  step =  600  of total steps  805  loss =  0.48156988620758057\n",
      "epoch =  37  step =  800  of total steps  805  loss =  0.5638348261515299\n",
      "epoch :  38  /  100  | TL :  0.5346025803567951  | VL :  0.5976677536964417\n",
      "saving model\n",
      "epoch =  38  step =  200  of total steps  805  loss =  0.4815487066904704\n",
      "epoch =  38  step =  400  of total steps  805  loss =  0.5712977250417074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-48fdf9109fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mproc_batch\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"Process batch `b` of `TensorImage`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36m_normalize_batch\u001b[0;34m(b, mean, std, do_x, do_y)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_y\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr = 1e-4)\n",
    "num_epochs = 100\n",
    "total_step = len(data.train_ds) // batch_size\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    net.train()\n",
    "    for i, (images, labels) in enumerate(data.train_dl) :\n",
    "        loss = 0.0\n",
    "        if torch.cuda.is_available():\n",
    "            images = torch.autograd.Variable(images).cuda().float()\n",
    "            labels = torch.autograd.Variable(labels).cuda()\n",
    "        else : \n",
    "            images = torch.autograd.Variable(images).float()\n",
    "            labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        y_pred = net(images)\n",
    "        y_pred2 = mdl(images)\n",
    "        \n",
    "        for k in range(5) : \n",
    "            loss += F.mse_loss(sf[k].features, sf2[k].features)\n",
    "        \n",
    "        loss += F.cross_entropy(y_pred, labels)\n",
    "        trn.append(loss.item() / 6)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 200 == 199 :\n",
    "            print('epoch = ', epoch, ' step = ', i + 1, ' of total steps ', total_step, ' loss = ', loss.item() / 6)\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(data.valid_dl) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = torch.autograd.Variable(images).cuda().float()\n",
    "                labels = torch.autograd.Variable(labels).cuda()\n",
    "            else : \n",
    "                images = torch.autograd.Variable(images).float()\n",
    "                labels = torch.autograd.Variable(labels)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch + 1, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(net.state_dict(), '../saved_models/model0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../saved_models/model5.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fec25e5c5673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learn = Learner(data, net, metrics = accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../saved_models/model5.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../saved_models/model5.pt'"
     ]
    }
   ],
   "source": [
    "# learn = Learner(data, net, metrics = accuracy)\n",
    "net.load_state_dict(torch.load('../saved_models/model5.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f70afc42898>,\n",
       " <matplotlib.lines.Line2D at 0x7f70b0bf9a90>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(38), train_loss_list, range(38), val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.92 GiB total capacity; 3.14 GiB already allocated; 8.50 MiB free; 198.26 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a73d64e37ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0m_get_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-a73d64e37ce7>\u001b[0m in \u001b[0;36m_get_accuracy\u001b[0;34m(dataloader, Net)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    144\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    145\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 494\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m max_pool2d = torch._jit_internal.boolean_dispatch(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.92 GiB total capacity; 3.14 GiB already allocated; 8.50 MiB free; 198.26 MiB cached)"
     ]
    }
   ],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = torch.autograd.Variable(images).float()\n",
    "        labels = torch.autograd.Variable(labels).float()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net.forward(images)\n",
    "        outputs = F.log_softmax(outputs, dim = 1)\n",
    "\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = labels - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "_get_accuracy(data.valid_dl, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    Flatten(),\n",
    "    nn.Linear(512 * 7 * 7, 512),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training without teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  50  of total steps  201  loss =  1.755843997001648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1045fc5ee311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr = 1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "total_step = len(data.train_ds) // batch_size\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    net.train()\n",
    "    for i, (images, labels) in enumerate(data.train_dl) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = torch.autograd.Variable(images).cuda().float()\n",
    "            labels = torch.autograd.Variable(labels).cuda()\n",
    "        else : \n",
    "            images = torch.autograd.Variable(images).float()\n",
    "            labels = torch.autograd.Variable(labels)\n",
    "\n",
    "        y_pred = net(images)\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, labels)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 49 :\n",
    "            print('epoch = ', epoch, ' step = ', i + 1, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(data.valid_dl) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = torch.autograd.Variable(images).cuda().float()\n",
    "                labels = torch.autograd.Variable(labels).cuda()\n",
    "            else : \n",
    "                images = torch.autograd.Variable(images).float()\n",
    "                labels = torch.autograd.Variable(labels)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc = _get_accuracy(data.valid_dl, net)\n",
    "    print('epoch : ', epoch + 1, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss, ' | VA : ', val_acc * 100)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(net.state_dict(), '../saved_models/model1_normal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('../saved_models/model4_normal.pt'))\n",
    "_get_accuracy(data.valid_dl, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate(folder_name, net) :\n",
    "    acc_list = list()\n",
    "    for i in range(5) : \n",
    "        filename = '../saved_models/' + folder_name + '/model' + str(i) + '.pt'\n",
    "        net.load_state_dict(torch.load(filename))\n",
    "        acc_list.append(_get_accuracy(data.valid_dl, net))\n",
    "\n",
    "    acc_list = [i * 100 for i in acc_list]\n",
    "    print(acc_list)\n",
    "    print(np.mean(acc_list))\n",
    "    print(np.std(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_evaluate('normal', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ak_fastai)",
   "language": "python",
   "name": "ak_fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
