{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "torch.cuda.set_device(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "# stage should be in 0 to 5 and for 0, use -1 (this is due to inconsistency in the model generated by PyTorch)\n",
    "hyper_params = {\n",
    "    \"stage\": 0,\n",
    "    \"repeated\": 1,\n",
    "    \"num_classes\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 1e-4\n",
    "}\n",
    "\n",
    "def save_torch(name:str, tensor):\n",
    "    new = tensor.clone()\n",
    "    np.save(name, new.detach().cpu().numpy())\n",
    "    \n",
    "def load_np_torch(name):\n",
    "    return torch.from_numpy(np.load(str(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/navid/.fastai/data/imagenette/train_feat/0'),\n",
       " PosixPath('/home/navid/.fastai/data/imagenette/train_feat/2'),\n",
       " PosixPath('/home/navid/.fastai/data/imagenette/train_feat/1'),\n",
       " PosixPath('/home/navid/.fastai/data/imagenette/train_feat/4'),\n",
       " PosixPath('/home/navid/.fastai/data/imagenette/train_feat/5'),\n",
       " PosixPath('/home/navid/.fastai/data/imagenette/train_feat/3')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train_feat = path/'train_feat'\n",
    "path_val_feat = path/'val_feat'\n",
    "\n",
    "path_train_feat.mkdir(exist_ok=True)\n",
    "path_val_feat.mkdir(exist_ok=True)\n",
    "\n",
    "for i in range(0, 6):\n",
    "    (path_train_feat/str(i)).mkdir(exist_ok=True)\n",
    "    (path_val_feat/str(i)).mkdir(exist_ok=True)\n",
    "    \n",
    "path_train_feat.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures :\n",
    "    def __init__(self, m) : \n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp) : \n",
    "        self.features = outp\n",
    "    def remove(self) :\n",
    "        self.handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_folder(path, train = 'train', valid = 'val', bs = hyper_params[\"batch_size\"], size = 224).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics = accuracy)\n",
    "learn.freeze()\n",
    "\n",
    "mdl = learn.model\n",
    "summary(mdl, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = [SaveFeatures(m) for m in [mdl[0][2], mdl[0][4], mdl[0][5], mdl[0][6], mdl[0][7]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(mdl=mdl, data=data):\n",
    "    mdl.eval()\n",
    "    for j in [\"train\", \"val\"]:\n",
    "        if j == \"train\" : dataset = data.train_ds\n",
    "        else: dataset = data.valid_ds       \n",
    "        for i in tqdm(range(len(dataset))) :\n",
    "            image = dataset[i][0]\n",
    "            name = dataset.items[i]\n",
    "            lst = str(name).split(j)\n",
    "            tensor = image.data.cuda().view(1, 3, 224, 224)\n",
    "            _ = mdl(tensor)\n",
    "        \n",
    "            for idx, feature in enumerate(sf):  \n",
    "                if j == \"train\":\n",
    "#                     image.save(f\"{lst[0]}{j}_images/{lst[1].split('/')[2].split('.')[0]}.JPEG\")\n",
    "                    save_torch(f\"{lst[0]}{j}_feat/{idx+1}/{lst[1].split('/')[2].split('.')[0]}.npy\",\n",
    "                              feature.features)\n",
    "                if j == \"val\":\n",
    "#                     image.save(f\"{lst[0]}{j}_images/{lst[1].split('/')[1] + lst[-1]}\")\n",
    "                    save_torch(f\"{lst[0]}{j}_feat/{idx+1}/{(lst[1].split('/')[1] + lst[-1])[:-4]}npy\",\n",
    "                              feature.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12894/12894 [14:45<00:00, 14.57it/s] \n",
      "100%|██████████| 500/500 [00:38<00:00, 13.12it/s]\n"
     ]
    }
   ],
   "source": [
    "save_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images():\n",
    "    for j in [\"train\", \"val\"]:\n",
    "        if j == \"train\" : dataset = data.train_ds\n",
    "        else: dataset = data.valid_ds       \n",
    "        for i in tqdm(range(len(dataset))) :\n",
    "            image = dataset[i][0].data \n",
    "            name = dataset.items[i]\n",
    "            lst = str(name).split(j)\n",
    "            if j == \"train\":\n",
    "                    save_torch(f\"{lst[0]}{j}_feat/0/{lst[1].split('/')[2].split('.')[0]}.npy\",\n",
    "                              image)\n",
    "            if j == \"val\":\n",
    "                save_torch(f\"{lst[0]}{j}_feat/0/{(lst[1].split('/')[1] + lst[-1])[:-4]}npy\",\n",
    "                              image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12894/12894 [06:02<00:00, 35.61it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 40.79it/s]\n"
     ]
    }
   ],
   "source": [
    "save_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FASTAI",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
